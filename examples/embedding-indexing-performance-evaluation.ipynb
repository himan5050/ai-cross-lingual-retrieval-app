{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e9f2e9-4968-424c-a831-05936d02612c",
   "metadata": {},
   "source": [
    "### 1. Performance and Load testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410818ab",
   "metadata": {},
   "source": [
    "This jupyter notebook is used to test performance and load testing while indexing large amount of dataset document files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff6981",
   "metadata": {},
   "source": [
    "### Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9706adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and faiss for model and vector indexing.\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "# Import time for performance measurement.\n",
    "import time\n",
    "\n",
    "# Import other required libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import SentenceTransformer for embedding generation.\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Ignore warnings for cleaner output.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Import pickle for saving and loading objects.\n",
    "import pickle\n",
    "\n",
    "# Import sqlite3 for database operations.\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79855c",
   "metadata": {},
   "source": [
    "#### Check device type and versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7731d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Device: CPU\n",
      "FAISS version: 1.7.4\n"
     ]
    }
   ],
   "source": [
    "# Check pytorch device\n",
    "print(\"PyTorch Device:\", \"GPU\" if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"FAISS version:\", faiss.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3881c",
   "metadata": {},
   "source": [
    "Check FAISS mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d206b96c-9e35-4e48-a25c-c448cc7c188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS is running in CPU mode.\n"
     ]
    }
   ],
   "source": [
    "if faiss.get_num_gpus() > 0:\n",
    "    print(f\"FAISS is GPU-enabled. GPUs detected: {faiss.get_num_gpus()}\")\n",
    "else:\n",
    "    print(\"FAISS is running in CPU mode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85863f01",
   "metadata": {},
   "source": [
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27ae4b",
   "metadata": {},
   "source": [
    "## Performance testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371077f",
   "metadata": {},
   "source": [
    "### 1. Load large amount of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "acc7829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy dataset of 1000 sentences\n",
    "sentences = [f\"This is sample sentence number {i}\" for i in range(2000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bb9e5",
   "metadata": {},
   "source": [
    "### 2. Load input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec92736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained SentenceTransformer model\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(model_name, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd30c2",
   "metadata": {},
   "source": [
    "### 3. Benchmarking embedding performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13902a63-f1c6-4c5d-b562-91b9cc8d5421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf5a22861a54175946d5baea60f4c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding 2000 sentences took: 6.14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: Encoding\n",
    "start_time = time.time()\n",
    "embeddings = model.encode(sentences, batch_size=256, show_progress_bar=True)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nEncoding 2000 sentences took: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2709bf",
   "metadata": {},
   "source": [
    "### 4. Convert embeddings to numpy \"Float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bbc89ae-5451-4286-b691-d89531b4e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to numpy float32\n",
    "embeddings = np.array(embeddings, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead9c44",
   "metadata": {},
   "source": [
    "### 5. Create FAISS indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fb0c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing 2000 embeddings took: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: FAISS Indexing.\n",
    "d = embeddings.shape[1]  # Dimension of the embeddings\n",
    "index = faiss.IndexFlatL2(d)  # Create a FAISS index\n",
    "if faiss.get_num_gpus() > 0:\n",
    "    index = faiss.index_cpu_to_all_gpus(index)  # Move index to GPU if available\n",
    "start_time = time.time()\n",
    "index.add(embeddings)  # Add embeddings to the index\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Indexing 2000 embeddings took: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fee366",
   "metadata": {},
   "source": [
    "### 6. Save FAISS index to disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "381a5d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to 'faiss_index.bin'\n"
     ]
    }
   ],
   "source": [
    "# Save the FAISS index to disk\n",
    "# Write indexes.\n",
    "faiss.write_index(index, \"my_index.faiss\")\n",
    "print(\"FAISS index saved to 'faiss_index.bin'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c08dc",
   "metadata": {},
   "source": [
    "### 7. Load index later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "517da220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded from 'faiss_index.bin'\n"
     ]
    }
   ],
   "source": [
    "# Load the FAISS index from disk\n",
    "index = faiss.read_index(\"my_index.faiss\")\n",
    "if faiss.get_num_gpus() > 0:\n",
    "    index = faiss.index_cpu_to_all_gpus(index)  # Move index to GPU if available\n",
    "print(\"FAISS index loaded from 'faiss_index.bin'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f96dd",
   "metadata": {},
   "source": [
    "### 8. Perform a search query (Evaluation step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd97a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search took: 0.0006 seconds\n",
      "Top results: [ 330  136 1364 1361 1366]\n"
     ]
    }
   ],
   "source": [
    "# Perform a sample search\n",
    "query = model.encode([\"This is a query sentence\"], convert_to_numpy=True)\n",
    "\n",
    "# Evaluate search performance.\n",
    "start_time = time.time()\n",
    "D, I = index.search(query.astype(\"float32\"), k=5)  # Top-5 results\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"Search took: {elapsed:.4f} seconds\")\n",
    "print(\"Top results:\", I[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f0cda",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bac7f8-8123-42be-9096-b21520521f3b",
   "metadata": {},
   "source": [
    "## Scalable Embedding and FAISS Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b36583",
   "metadata": {},
   "source": [
    "### 1. Get embedding dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40bcedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy dataset of 1000 sentences\n",
    "sentences = [f\"This is sample sentence number {i}\" for i in range(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e2f7856-31e6-4f87-8952-fb462ed705df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentence embedding dimension.\n",
    "embedding_dim = model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c6f98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS index.\n",
    "index = faiss.IndexFlatL2(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95863f22-d0fe-4ac1-b468-e79d30c32a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is available, use FAISS GPU\n",
    "if faiss.get_num_gpus() > 0:\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.index_cpu_to_gpu(res, 0, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da13749",
   "metadata": {},
   "source": [
    "### 2. Encode in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d91be1fb-600f-4b89-8a43-352bf3358113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch encoding function\n",
    "def encode_in_batches(texts, batch_size=128):\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        yield texts[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82aacdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac37e2556ba4b9096696c77e612eb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b649e4a5c0354d4b8b435874c00c928c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db290b613cc44959b2369a1b361d899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227d73e9f6c5427f88ba76f8c7538eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe801d294cb64740a4f9c36b0c352cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9580b15fbf6540fc9004f4eb93276075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac91421495440b69238264a423f9f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4b3b374e244345b1cb4b9d057671e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding 2000000 sentences took: 14.26 seconds\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: Encoding \n",
    "start_time = time.time()\n",
    "batch_size = 256\n",
    "for batch in encode_in_batches(sentences, batch_size=batch_size):\n",
    "    embeddings = model.encode(batch, batch_size=batch_size, convert_to_numpy=True, show_progress_bar=True)\n",
    "    embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "    index.add(embeddings)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nEncoding 2000 sentences took: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c62abc4d-2aea-4bfd-ac3a-3c8820edd3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished indexing all documents\n",
      "Total vectors in index: 6000\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished indexing all documents\")\n",
    "print(\"Total vectors in index:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec26a1f",
   "metadata": {},
   "source": [
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23e04d-f7a7-4583-b0f8-cfcbdc029a42",
   "metadata": {},
   "source": [
    "### FAISS + Metadata storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d45ce31",
   "metadata": {},
   "source": [
    "Store document IDs + Metadata (title, text, etc.) along side FAISS embeddings, this will help to retrieve full documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573e1b3",
   "metadata": {},
   "source": [
    "### 1. Get the sample dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd15f51f-8a6c-4a56-946c-7f90193bf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataframe (replace with your real dataset)\n",
    "data = pd.DataFrame({\n",
    "    \"id\": range(1, 6),\n",
    "    \"title\": [f\"Title {i}\" for i in range(1, 6)],\n",
    "    \"text\": [f\"This is the text of document {i}\" for i in range(1, 6)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "830f8353-e9b6-4ed7-a20d-a4fe61e381c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Title 1</td>\n",
       "      <td>This is the text of document 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Title 2</td>\n",
       "      <td>This is the text of document 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Title 3</td>\n",
       "      <td>This is the text of document 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Title 4</td>\n",
       "      <td>This is the text of document 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Title 5</td>\n",
       "      <td>This is the text of document 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    title                            text\n",
       "0   1  Title 1  This is the text of document 1\n",
       "1   2  Title 2  This is the text of document 2\n",
       "2   3  Title 3  This is the text of document 3\n",
       "3   4  Title 4  This is the text of document 4\n",
       "4   5  Title 5  This is the text of document 5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6038d0",
   "metadata": {},
   "source": [
    "### 2. Build metadata mapping : Index -> Document info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f0fd77d-d982-4c6b-bd2d-b9e296fa03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build metadata mapping: index -> document info\n",
    "metadata_store = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e76f0",
   "metadata": {},
   "source": [
    "### 3. Setup FAISS index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c59885c8-639e-4ab9-829e-791939648294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup FAISS index\n",
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "index = faiss.IndexFlatL2(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "253b945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU available, move FAISS to GPU\n",
    "if faiss.get_num_gpus() > 0:\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.index_cpu_to_gpu(res, 0, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509158bc",
   "metadata": {},
   "source": [
    "### 4. Embedding and Indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75e97fc3-2428-46c1-895e-1af4622ea768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and add in batches\n",
    "batch_size = 2\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9da1b690-ab64-49f2-a0d2-183a096c5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data.iloc[i:i+batch_size]\n",
    "    embeddings = model.encode(batch[\"text\"].tolist(), batch_size=batch_size, convert_to_numpy=True)\n",
    "    embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    # Store metadata alongside embeddings\n",
    "    for j, row in batch.iterrows():\n",
    "        metadata_store[counter] = {\n",
    "            \"id\": row[\"id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"text\": row[\"text\"]\n",
    "        }\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea4fc45a-e1e3-4421-9e83-72a5defb7d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished indexing\n",
      "Total vectors: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Finished indexing\")\n",
    "print(\"Total vectors:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803fec2",
   "metadata": {},
   "source": [
    "### 5. Query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90dcca2e-e65c-46a5-92d5-0c3246cbe62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"sample text document\"\n",
    "query_vec = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "D, I = index.search(query_vec, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51e800c",
   "metadata": {},
   "source": [
    "### 6. Retrieve full document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "565b9d12-456d-4a7b-85c9-43895b1e18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top results:\n",
      "Score: 0.9075 | ID: 1 | Title: Title 1 | Text: This is the text of document 1\n",
      "Score: 0.9481 | ID: 5 | Title: Title 5 | Text: This is the text of document 5\n",
      "Score: 0.9796 | ID: 2 | Title: Title 2 | Text: This is the text of document 2\n"
     ]
    }
   ],
   "source": [
    "# Retrieve full documents\n",
    "print(\"\\nTop results:\")\n",
    "for idx, score in zip(I[0], D[0]):\n",
    "    doc = metadata_store[idx]\n",
    "    print(f\"Score: {score:.4f} | ID: {doc['id']} | Title: {doc['title']} | Text: {doc['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25073895",
   "metadata": {},
   "source": [
    "********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b407ce9f-0dc1-4d10-a2e4-cabb552790fa",
   "metadata": {},
   "source": [
    "### Save & Load FAISS + Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ac41b1c-bd57-4a4b-a775-750a9affe801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SAVE =====\n",
    "def save_faiss_with_metadata(index, metadata_store, faiss_path=\"my_index.faiss\", meta_path=\"metadata.pkl\"):\n",
    "    # Save FAISS index\n",
    "    faiss.write_index(index, faiss_path)\n",
    "    # Save metadata (Python dict) using pickle\n",
    "    with open(meta_path, \"wb\") as f:\n",
    "        pickle.dump(metadata_store, f)\n",
    "    print(f\" Saved FAISS index to {faiss_path} and metadata to {meta_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6152b2f-0c5c-4806-a8bb-a009372b193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LOAD =====\n",
    "def load_faiss_with_metadata(faiss_path=\"my_index.faiss\", meta_path=\"metadata.pkl\"):\n",
    "    # Load FAISS index\n",
    "    index = faiss.read_index(faiss_path)\n",
    "    # Load metadata\n",
    "    with open(meta_path, \"rb\") as f:\n",
    "        metadata_store = pickle.load(f)\n",
    "    print(f\" Loaded FAISS index and metadata (docs: {len(metadata_store)})\")\n",
    "    return index, metadata_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96bad577-4c47-4c0a-adf8-8be3f5258b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved FAISS index to my_index.faiss and metadata to metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "# === Example Usage ===\n",
    "# Suppose `index` and `metadata_store` exist from your embedding step:\n",
    "save_faiss_with_metadata(index, metadata_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd065088-f351-47aa-98a7-faefe30a10c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded FAISS index and metadata (docs: 5)\n"
     ]
    }
   ],
   "source": [
    "# Later (in a new session / notebook):\n",
    "index, metadata_store = load_faiss_with_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a046f15-de1d-45fa-8aa2-eb16e59d76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query after reload\n",
    "query = \"sample text document\"\n",
    "query_vec = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "D, I = index.search(query_vec, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5387221b-cf57-4cec-80c0-1f61e8197213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top results:\n",
      "Score: 0.9075 | ID: 1 | Title: Title 1 | Text: This is the text of document 1\n",
      "Score: 0.9481 | ID: 5 | Title: Title 5 | Text: This is the text of document 5\n",
      "Score: 0.9796 | ID: 2 | Title: Title 2 | Text: This is the text of document 2\n"
     ]
    }
   ],
   "source": [
    "# Retrieve full documents\n",
    "print(\"\\nTop results:\")\n",
    "for idx, score in zip(I[0], D[0]):\n",
    "    doc = metadata_store[idx]\n",
    "    print(f\"Score: {score:.4f} | ID: {doc['id']} | Title: {doc['title']} | Text: {doc['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24969db2",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b52ebc-0424-4648-bf02-db30655736dd",
   "metadata": {},
   "source": [
    "# <b>Recommended approach: Hybrid model, Using SQLLite for Metadata storage and FAISS vector database for index storage.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39e7bf6",
   "metadata": {},
   "source": [
    "### 1. Setup SQLite Database for Metadata Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50f36bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IGNORE ---\n",
    "### 1. Setup SQLite Database for Metadata Storage.\n",
    "connection = sqlite3.connect('metadata_storage.db')\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d21a8",
   "metadata": {},
   "source": [
    "Create table for documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4e9809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS documents (\n",
    "    doc_id INTEGER PRIMARY KEY,\n",
    "    title TEXT,\n",
    "    text TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1fb33511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "documents = [\n",
    "    {\"title\": \"Doc 1\", \"text\": \"This is the first document\"},\n",
    "    {\"title\": \"Doc 2\", \"text\": \"This is the second document\"},\n",
    "    {\"title\": \"Doc 3\", \"text\": \"Another document for testing\"},\n",
    "    {\"title\": \"Doc 4\", \"text\": \"Another document Himanshu for testing4\"},\n",
    "    {\"title\": \"Doc 5\", \"text\": \"Another document Engineer for testing 5\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d7d3091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Doc 1', 'text': 'This is the first document'},\n",
       " {'title': 'Doc 2', 'text': 'This is the second document'},\n",
       " {'title': 'Doc 3', 'text': 'Another document for testing'},\n",
       " {'title': 'Doc 4', 'text': 'Another document Himanshu for testing4'},\n",
       " {'title': 'Doc 5', 'text': 'Another document Engineer for testing 5'}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c33dd",
   "metadata": {},
   "source": [
    "### 2. Insert Metadata while indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3db23376-2583-4929-a7f0-a081fd70cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Indexed documents in FAISS + SQLite\n"
     ]
    }
   ],
   "source": [
    "# Load input model\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# FAISS index\n",
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "# Insert documents and add embeddings\n",
    "for doc in documents:\n",
    "    # Save metadata in SQLite\n",
    "    cursor.execute(\"INSERT INTO documents (title, text) VALUES (?, ?)\", (doc[\"title\"], doc[\"text\"]))\n",
    "    doc_id = cursor.lastrowid  # SQLite assigns unique ID\n",
    "    \n",
    "    # Encode and add to FAISS\n",
    "    embedding = model.encode([doc[\"text\"]], convert_to_numpy=True).astype(\"float32\")\n",
    "    index.add(embedding)\n",
    "\n",
    "# Commit changes to SQLite.\n",
    "connection.commit()\n",
    "\n",
    "print(\"✅ Indexed documents in FAISS + SQLite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2bb6e",
   "metadata": {},
   "source": [
    "### 3. Save and Reload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "efdf9988-eff1-48ec-b147-49bd207a3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "faiss.write_index(index, \"faiss_index.faiss\")\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ee2b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later reload:\n",
    "index = faiss.read_index(\"faiss_index.faiss\")\n",
    "conn = sqlite3.connect(\"metadata_storage.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f5c8b",
   "metadata": {},
   "source": [
    "### 4. Query with FAISS + Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e573ea14-a862-457e-a7c7-d6b40bf68605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query FAISS\n",
    "query = \"find a test document\"\n",
    "query_vec = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "D, I = index.search(query_vec, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3e253aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[10.7447405, 18.093216 , 19.046337 ]], dtype=float32),\n",
       " array([[2, 3, 4]]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5e1853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search results:\n"
     ]
    }
   ],
   "source": [
    "# Fetch metadata from SQLite\n",
    "print(\"\\nSearch results:\")\n",
    "for idx, score in zip(I[0], D[0]):\n",
    "    # SQLite doc_id is 1-based, FAISS index is 0-based → offset by +1\n",
    "    cursor.execute(\"SELECT doc_id, title, text FROM documents WHERE doc_id=?\", (idx+1,))\n",
    "    row = cursor.fetchone()\n",
    "    if row:\n",
    "        print(f\"Score: {score:.4f} | ID: {row[0]} | Title: {row[1]} | Text: {row[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937346f",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33ea13",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-lingual-semantic-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

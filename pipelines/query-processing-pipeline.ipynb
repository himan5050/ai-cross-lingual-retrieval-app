{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc03c3a1",
   "metadata": {},
   "source": [
    "# Query processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b865727",
   "metadata": {},
   "source": [
    "#### 1. Setup: load model, tokenizer, FAISS index, and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5466fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, torch, faiss\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --- Paths you already created earlier ---\n",
    "META_PATH   = \"data/embeddings_fast/paraphrase-multilingual-MiniLM-L12-v2_passages_meta.parquet\"   # replace\n",
    "FAISS_PATH  = \"data/faiss_index/passages_flatip.faiss\"                # replace\n",
    "\n",
    "# Choose model (speed tiers):\n",
    "# FAST:    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" (384d)\n",
    "# BALANCE: \"intfloat/multilingual-e5-base\" (768d)\n",
    "# QUALITY: \"intfloat/multilingual-e5-large\" (1024d)\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "# --- Load meta and FAISS ---\n",
    "meta  = pd.read_parquet(META_PATH)          # must include global_chunk_id, doc_id, chunk_id, title, preview, site, lang, ...\n",
    "index = faiss.read_index(FAISS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec564439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model / tokenizer ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE  = torch.float16 if DEVICE.type == \"cuda\" else torch.float32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model     = AutoModel.from_pretrained(MODEL_NAME, torch_dtype=(torch.float16 if DEVICE.type==\"cuda\" else None)).to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ddfb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_token_budget(tok, headroom=16, cap_default=512):\n",
    "    m = getattr(tok, \"model_max_length\", None)\n",
    "    if m is None or m > 100_000_000: m = cap_default\n",
    "    return max(32, int(m - headroom))\n",
    "TOKEN_BUDGET = model_token_budget(tokenizer)\n",
    "\n",
    "# E5 uses \"query: \" prefix. Others don't.\n",
    "def add_query_prefix(texts):\n",
    "    return [f\"query: {t}\" for t in texts] if \"intfloat/multilingual-e5\" in MODEL_NAME.lower() else texts\n",
    "\n",
    "@torch.no_grad()\n",
    "def mean_pool(last_hidden_state, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
    "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
    "\n",
    "def l2_normalize_np(x: np.ndarray) -> np.ndarray:\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True) + 1e-12\n",
    "    return x / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201d6d4",
   "metadata": {},
   "source": [
    "### 1. Batch embed queries (fast, safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216de71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_queries(queries: list[str], batch_size: int = 128) -> np.ndarray:\n",
    "    \"\"\"Return (Q, d) L2-normalized float32 embeddings for queries.\"\"\"\n",
    "    vecs = []\n",
    "    queries = add_query_prefix([str(q) for q in queries])\n",
    "    for i in tqdm(range(0, len(queries), batch_size), desc=\"Embedding queries\", unit=\"batch\"):\n",
    "        batch = queries[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=TOKEN_BUDGET, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(DEVICE, non_blocking=True) for k, v in enc.items()}\n",
    "        with torch.inference_mode(), (\n",
    "            torch.autocast(device_type=DEVICE.type, dtype=torch.float16) if DEVICE.type==\"cuda\" else torch.no_grad()\n",
    "        ):\n",
    "            out    = model(**enc)\n",
    "            pooled = mean_pool(out.last_hidden_state, enc[\"attention_mask\"])\n",
    "            pooled = torch.nn.functional.normalize(pooled, p=2, dim=1)   # cosine тЖТ IP\n",
    "        vecs.append(pooled.to(torch.float32).cpu().numpy())\n",
    "    return np.vstack(vecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb56499",
   "metadata": {},
   "source": [
    "### 2. Dense search (FAISS) for a batch of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ff3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faiss_search_batch(q_vecs: np.ndarray, top_k: int = 10) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    q_vecs: (Q, d) float32, L2-normalized\n",
    "    returns (scores, indices) each (Q, top_k) with cosine scores (via inner product).\n",
    "    \"\"\"\n",
    "    assert q_vecs.dtype == np.float32\n",
    "    D, I = index.search(q_vecs, top_k)\n",
    "    return D, I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ea5d5",
   "metadata": {},
   "source": [
    "### 3. Assemble results into a tidy DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0819cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_df(queries: list[str], D: np.ndarray, I: np.ndarray, meta: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a long DataFrame with one row per (query, hit).\n",
    "    Columns: query_id, query, rank, dense_score, global_chunk_id, doc_id, chunk_id, title, site, lang, preview, ...\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for qid, (scores, idxs) in enumerate(zip(D, I)):\n",
    "        m = meta.iloc[idxs].copy()\n",
    "        m = m.assign(\n",
    "            query_id = qid,\n",
    "            query    = queries[qid],\n",
    "            rank     = np.arange(1, len(idxs)+1),\n",
    "            dense_score = scores\n",
    "        )\n",
    "        rows.append(m)\n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "    # Ensure IDs exist\n",
    "    if \"global_chunk_id\" not in df.columns:\n",
    "        df[\"global_chunk_id\"] = df[\"doc_id\"].astype(str) + \":\" + df[\"chunk_id\"].astype(int).astype(str)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc259f15",
   "metadata": {},
   "source": [
    "### 4. Optional: roll up chunk тЖТ document (max score per doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b45f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_level(df_hits: pd.DataFrame, top_k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep the best chunk per document for each query; then take top_k docs.\n",
    "    \"\"\"\n",
    "    # best chunk per (query_id, doc_id)\n",
    "    best = (df_hits.sort_values([\"query_id\",\"doc_id\",\"dense_score\"], ascending=[True, True, False])\n",
    "                 .groupby([\"query_id\",\"doc_id\"], as_index=False)\n",
    "                 .first())\n",
    "    # rerank per query by score\n",
    "    best[\"rank\"] = best.groupby(\"query_id\")[\"dense_score\"].rank(ascending=False, method=\"first\").astype(int)\n",
    "    best = best.sort_values([\"query_id\",\"rank\"]).groupby(\"query_id\").head(top_k).reset_index(drop=True)\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82340ae",
   "metadata": {},
   "source": [
    "### 5. One call: run a list of queries end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbedab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dense_pipeline(queries: list[str], top_k_chunks: int = 10, top_k_docs: int | None = None):\n",
    "    # 1) embed\n",
    "    q_vecs = embed_queries(queries)\n",
    "    q_vecs = q_vecs.astype(\"float32\")\n",
    "    q_vecs = l2_normalize_np(q_vecs)  # already normalized above; keep for safety\n",
    "\n",
    "    # 2) search\n",
    "    D, I = faiss_search_batch(q_vecs, top_k=top_k_chunks)\n",
    "\n",
    "    # 3) assemble\n",
    "    df_chunks = results_df(queries, D, I, meta)\n",
    "\n",
    "    # 4) optional doc-level rollup\n",
    "    df_docs = doc_level(df_chunks, top_k=top_k_docs) if top_k_docs else None\n",
    "    return df_chunks, df_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2547befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "queries = [\n",
    "    \"child immunization reduces mortality\",      # en\n",
    "    \"pol├нtica de vacunaci├│n infantil\",          # es\n",
    "    \"рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг\",                    # hi\n",
    "    \"хД┐члехЕНчЦлцОечзН хп╣ цн╗ф║бчОЗ чЪД х╜▒хУН\"                     # zh\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "033364a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e934548205334b1681294d4adef9fc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding queries:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_hits, df_docs = run_dense_pipeline(queries, top_k_chunks=20, top_k_docs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ed09e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>dense_score</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862851</td>\n",
       "      <td>15900</td>\n",
       "      <td>0</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>hi</td>\n",
       "      <td>рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдХреЗ рдХреНрд╖реЗрддреНрд░ рдореЗрдВ рдЯреАрдХрд╛рдХрд░рдг рдХрд╛ рдЕрд╣рдо рдпреЛрдЧрджрд╛рди ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797363</td>\n",
       "      <td>14211</td>\n",
       "      <td>5</td>\n",
       "      <td>╪з┘Д┘К┘И┘Ж┘К╪│┘Б ┘И┘Е┘Ж╪╕┘Е╪й ╪з┘Д╪╡╪н╪й ╪з┘Д╪╣╪з┘Д┘Е┘К╪й ╪к╪н╪░┘С┘Р╪▒╪з┘Ж ┘Е┘Ж ╪з╪м╪к...</td>\n",
       "      <td>ar</td>\n",
       "      <td>┘Д╪┤╪▒╪н ╪г┘З┘Е┘К╪й ╪з┘Д┘Д┘В╪з╪н╪з╪к╪Ы ╪│╪п ╪з┘Д┘Б╪м┘И╪з╪к ┘Б┘К ╪к╪║╪╖┘К╪й ╪з┘Д╪к╪н╪╡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>3</td>\n",
       "      <td>0.776559</td>\n",
       "      <td>18018</td>\n",
       "      <td>4</td>\n",
       "      <td>╨Ч╨╝╤Ц╤Ж╨╜╨╡╨╜╨╜╤П ╨┤╨╛╨▓╤Ц╤А╨╕ ╨┤╨╛ ╨┐╤А╨╛╨┤╨╛╨▓╨╢╨╡╨╜╨╜╤П ╨┐╨╗╨░╨╜╨╛╨▓╨╛╤Ч ╤Ц╨╝╤Г╨╜╤Ц...</td>\n",
       "      <td>uk</td>\n",
       "      <td>╨║╨╗╤О╤З╨╛╨▓╨╕╤Е ╨╛╤Б╤Ц╨▒, ╤П╨║╤Ц ╨┐╤А╨╕╨╣╨╝╨░╤О╤В╤М ╤А╤Ц╤И╨╡╨╜╨╜╤П, ╨┐╨╛╨▓'╤П╨╖╨░╨╜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>4</td>\n",
       "      <td>0.767746</td>\n",
       "      <td>14644</td>\n",
       "      <td>3</td>\n",
       "      <td>Dix-huit millions de doses du tout premier vac...</td>\n",
       "      <td>fr</td>\n",
       "      <td>├иs et traiter la maladie depuis longtemps, mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>5</td>\n",
       "      <td>0.763638</td>\n",
       "      <td>13699</td>\n",
       "      <td>5</td>\n",
       "      <td>╪о╪п┘Е╪з╪к ╪з┘Д╪к╪н╪╡┘К┘Ж ╪к╪и╪п╪г ╪и╪з┘Д╪к╪╣╪з┘Б┘К ╪и╪и╪╖╪б ┘Е┘Ж ╪з┘Д╪к╪╣╪╖┘К┘Д╪з╪к ...</td>\n",
       "      <td>ar</td>\n",
       "      <td>╪з╪л ┘И╪з┘Д╪к╪╖┘И┘К╪▒ ┘Б┘К ┘Е╪м╪з┘Д ╪з┘Д┘Д┘В╪з╪н╪з╪к╪М ┘И╪╢┘Е╪з┘Ж ╪з╪│╪к┘Е╪▒╪з╪▒┘К╪й ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>6</td>\n",
       "      <td>0.744338</td>\n",
       "      <td>8669</td>\n",
       "      <td>2</td>\n",
       "      <td>123,000 children in Europe and Central Asia ar...</td>\n",
       "      <td>en</td>\n",
       "      <td>combination of the number of vaccines in a cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>7</td>\n",
       "      <td>0.743962</td>\n",
       "      <td>20165</td>\n",
       "      <td>2</td>\n",
       "      <td>╨о╨Э╨Ж╨б╨Х╨д ╨┤╨╛╤Б╤В╨░╨▓╨╕╨▓ ╨▓ ╨г╨║╤А╨░╤Ч╨╜╤Г 340 ╤В╨╕╤Б╤П╤З ╨┤╨╛╨╖ ╨╛╤А╨░╨╗╤М╨╜...</td>\n",
       "      <td>uk</td>\n",
       "      <td>╨┤╨╛╨┐╨╛╨╝╨╛╨│╨╛╤О ╤Й╨╡╨┐╨╗╨╡╨╜╤М. ╨Ю╨║╤А╤Ц╨╝ ╤В╨╛╨│╨╛, ╨░╨▒╨╕ ╨╖╨░╨▒╨╡╨╖╨┐╨╡╤З╨╕╤В╨╕...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>8</td>\n",
       "      <td>0.735053</td>\n",
       "      <td>4424</td>\n",
       "      <td>2</td>\n",
       "      <td>хСКшпЙф╜ачЦлшЛЧщВгф║Ыф║ЛхД┐</td>\n",
       "      <td>zh</td>\n",
       "      <td>ф╝ацТнхЗ║хО╗)уАВ цЦ░ц╡кхЫ╜щЩЕ:цОечзНчЦлшЛЧхп╣хнйхнРцЬЙф╗Аф╣Ихе╜хдД? цЬ▒х╛Р: цЬЙф║Ы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>9</td>\n",
       "      <td>0.728540</td>\n",
       "      <td>19340</td>\n",
       "      <td>6</td>\n",
       "      <td>╨Т╨Ю╨Ю╨Ч ╤В╨░ ╨о╨Э╨Ж╨б╨Х╨д ╨╖╨░╤Б╤В╨╡╤А╤Ц╨│╨░╤О╤В╤М ╤Й╨╛╨┤╨╛ ╨╖╨╜╨╕╨╢╨╡╨╜╨╜╤П ╤А╤Ц╨▓╨╜...</td>\n",
       "      <td>uk</td>\n",
       "      <td>╤В╨░ ╨┐╤А╨╛╤Д╤Ц╨╗╨░╨║╤В╨╕╨║╨╕ ╨╖╨░╤Е╨▓╨╛╤А╤О╨▓╨░╨╜╤М ╨▓ ╨б╨и╨Р (CDC), ╨Ж╨╜╤Б╤В╨╕...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг</td>\n",
       "      <td>10</td>\n",
       "      <td>0.727539</td>\n",
       "      <td>13216</td>\n",
       "      <td>8</td>\n",
       "      <td>80 millions d'enfants de moins dтАЩun an risquen...</td>\n",
       "      <td>fr</td>\n",
       "      <td>i, l'Alliance du Vaccin. Son objectif est d'├йr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id                                        query  rank  dense_score  \\\n",
       "40         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     1     0.862851   \n",
       "41         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     2     0.797363   \n",
       "42         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     3     0.776559   \n",
       "43         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     4     0.767746   \n",
       "44         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     5     0.763638   \n",
       "45         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     6     0.744338   \n",
       "46         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     7     0.743962   \n",
       "47         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     8     0.735053   \n",
       "48         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг     9     0.728540   \n",
       "49         2  рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг    10     0.727539   \n",
       "\n",
       "    doc_id  chunk_id                                              title lang  \\\n",
       "40   15900         0        рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг   hi   \n",
       "41   14211         5  ╪з┘Д┘К┘И┘Ж┘К╪│┘Б ┘И┘Е┘Ж╪╕┘Е╪й ╪з┘Д╪╡╪н╪й ╪з┘Д╪╣╪з┘Д┘Е┘К╪й ╪к╪н╪░┘С┘Р╪▒╪з┘Ж ┘Е┘Ж ╪з╪м╪к...   ar   \n",
       "42   18018         4  ╨Ч╨╝╤Ц╤Ж╨╜╨╡╨╜╨╜╤П ╨┤╨╛╨▓╤Ц╤А╨╕ ╨┤╨╛ ╨┐╤А╨╛╨┤╨╛╨▓╨╢╨╡╨╜╨╜╤П ╨┐╨╗╨░╨╜╨╛╨▓╨╛╤Ч ╤Ц╨╝╤Г╨╜╤Ц...   uk   \n",
       "43   14644         3  Dix-huit millions de doses du tout premier vac...   fr   \n",
       "44   13699         5  ╪о╪п┘Е╪з╪к ╪з┘Д╪к╪н╪╡┘К┘Ж ╪к╪и╪п╪г ╪и╪з┘Д╪к╪╣╪з┘Б┘К ╪и╪и╪╖╪б ┘Е┘Ж ╪з┘Д╪к╪╣╪╖┘К┘Д╪з╪к ...   ar   \n",
       "45    8669         2  123,000 children in Europe and Central Asia ar...   en   \n",
       "46   20165         2  ╨о╨Э╨Ж╨б╨Х╨д ╨┤╨╛╤Б╤В╨░╨▓╨╕╨▓ ╨▓ ╨г╨║╤А╨░╤Ч╨╜╤Г 340 ╤В╨╕╤Б╤П╤З ╨┤╨╛╨╖ ╨╛╤А╨░╨╗╤М╨╜...   uk   \n",
       "47    4424         2                                          хСКшпЙф╜ачЦлшЛЧщВгф║Ыф║ЛхД┐   zh   \n",
       "48   19340         6  ╨Т╨Ю╨Ю╨Ч ╤В╨░ ╨о╨Э╨Ж╨б╨Х╨д ╨╖╨░╤Б╤В╨╡╤А╤Ц╨│╨░╤О╤В╤М ╤Й╨╛╨┤╨╛ ╨╖╨╜╨╕╨╢╨╡╨╜╨╜╤П ╤А╤Ц╨▓╨╜...   uk   \n",
       "49   13216         8  80 millions d'enfants de moins dтАЩun an risquen...   fr   \n",
       "\n",
       "                                              preview  \n",
       "40  рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдХреЗ рдХреНрд╖реЗрддреНрд░ рдореЗрдВ рдЯреАрдХрд╛рдХрд░рдг рдХрд╛ рдЕрд╣рдо рдпреЛрдЧрджрд╛рди ...  \n",
       "41  ┘Д╪┤╪▒╪н ╪г┘З┘Е┘К╪й ╪з┘Д┘Д┘В╪з╪н╪з╪к╪Ы ╪│╪п ╪з┘Д┘Б╪м┘И╪з╪к ┘Б┘К ╪к╪║╪╖┘К╪й ╪з┘Д╪к╪н╪╡...  \n",
       "42  ╨║╨╗╤О╤З╨╛╨▓╨╕╤Е ╨╛╤Б╤Ц╨▒, ╤П╨║╤Ц ╨┐╤А╨╕╨╣╨╝╨░╤О╤В╤М ╤А╤Ц╤И╨╡╨╜╨╜╤П, ╨┐╨╛╨▓'╤П╨╖╨░╨╜...  \n",
       "43  ├иs et traiter la maladie depuis longtemps, mai...  \n",
       "44  ╪з╪л ┘И╪з┘Д╪к╪╖┘И┘К╪▒ ┘Б┘К ┘Е╪м╪з┘Д ╪з┘Д┘Д┘В╪з╪н╪з╪к╪М ┘И╪╢┘Е╪з┘Ж ╪з╪│╪к┘Е╪▒╪з╪▒┘К╪й ...  \n",
       "45  combination of the number of vaccines in a cou...  \n",
       "46  ╨┤╨╛╨┐╨╛╨╝╨╛╨│╨╛╤О ╤Й╨╡╨┐╨╗╨╡╨╜╤М. ╨Ю╨║╤А╤Ц╨╝ ╤В╨╛╨│╨╛, ╨░╨▒╨╕ ╨╖╨░╨▒╨╡╨╖╨┐╨╡╤З╨╕╤В╨╕...  \n",
       "47                   ф╝ацТнхЗ║хО╗)уАВ цЦ░ц╡кхЫ╜щЩЕ:цОечзНчЦлшЛЧхп╣хнйхнРцЬЙф╗Аф╣Ихе╜хдД? цЬ▒х╛Р: цЬЙф║Ы  \n",
       "48  ╤В╨░ ╨┐╤А╨╛╤Д╤Ц╨╗╨░╨║╤В╨╕╨║╨╕ ╨╖╨░╤Е╨▓╨╛╤А╤О╨▓╨░╨╜╤М ╨▓ ╨б╨и╨Р (CDC), ╨Ж╨╜╤Б╤В╨╕...  \n",
       "49  i, l'Alliance du Vaccin. Son objectif est d'├йr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect\n",
    "df_hits[df_hits['query'] == 'рдЯреАрдХрд╛рдХрд░рдг рдХреНрдпреЛрдВ рдЬрд░реВрд░реА рд╣реИ рдЗрд╕рдХреЗ рдкрд╛рдВрдЪ рдореБрдЦреНрдп рдХрд╛рд░рдг'].head(10)[[\"query_id\",\"query\",\"rank\",\"dense_score\",\"doc_id\",\"chunk_id\",\"title\",\"lang\",\"preview\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0bb63",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fca18f",
   "metadata": {},
   "source": [
    "## <b>Query Evaluation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa5fc57",
   "metadata": {},
   "source": [
    "### 1. Helpers: roll up to doc-level (optional) and normalize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Iterable, Dict, List\n",
    "\n",
    "def to_doc_level(df_hits: pd.DataFrame, top_k: int | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Collapse chunk-level results to doc-level by keeping the best chunk per (query_id, doc_id),\n",
    "    then re-ranking by score. Assumes columns: query_id, doc_id, dense_score (or score), rank.\n",
    "    \"\"\"\n",
    "    score_col = \"dense_score\" if \"dense_score\" in df_hits.columns else \"score\"\n",
    "    if score_col not in df_hits.columns:\n",
    "        raise ValueError(\"df_hits must contain 'dense_score' or 'score' column.\")\n",
    "    # keep best chunk per (query, doc)\n",
    "    best = (df_hits\n",
    "            .sort_values([\"query_id\",\"doc_id\",score_col], ascending=[True, True, False])\n",
    "            .groupby([\"query_id\",\"doc_id\"], as_index=False)\n",
    "            .first())\n",
    "    # rerank within query\n",
    "    best[\"rank\"] = best.groupby(\"query_id\")[score_col].rank(ascending=False, method=\"first\").astype(int)\n",
    "    best = best.sort_values([\"query_id\",\"rank\"])\n",
    "    if top_k:\n",
    "        best = best.groupby(\"query_id\").head(top_k).reset_index(drop=True)\n",
    "    return best\n",
    "\n",
    "def load_ground_truth(gt_path_or_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expect columns: query_id, doc_id, relevant (0/1 or graded).\n",
    "    Keeps only rows with relevant > 0.\n",
    "    \"\"\"\n",
    "    gt = gt_path_or_df if isinstance(gt_path_or_df, pd.DataFrame) else pd.read_csv(gt_path_or_df)\n",
    "    # Basic sanity\n",
    "    required = {\"query_id\",\"doc_id\",\"relevant\"}\n",
    "    missing = required - set(gt.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Ground truth missing columns: {missing}\")\n",
    "    gt = gt.copy()\n",
    "    # Coerce types\n",
    "    gt[\"query_id\"] = gt[\"query_id\"].astype(int)\n",
    "    gt[\"doc_id\"]   = gt[\"doc_id\"].astype(str)\n",
    "    # Keep nonzero as relevant; preserve graded values for nDCG\n",
    "    gt = gt[gt[\"relevant\"] > 0].reset_index(drop=True)\n",
    "    return gt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77b7e6",
   "metadata": {},
   "source": [
    "### 2. Metrics (P@k, Recall@k, MRR, MAP, nDCG) тАФ binary or graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ba0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ranked_ids: List[str], relevant_set: set[str], k: int) -> float:\n",
    "    if k == 0: return 0.0\n",
    "    topk = ranked_ids[:k]\n",
    "    hits = sum(1 for x in topk if x in relevant_set)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(ranked_ids: List[str], relevant_set: set[str], k: int) -> float:\n",
    "    if not relevant_set: return 0.0\n",
    "    topk = ranked_ids[:k]\n",
    "    hits = sum(1 for x in topk if x in relevant_set)\n",
    "    return hits / len(relevant_set)\n",
    "\n",
    "def average_precision(ranked_ids: List[str], relevant_set: set[str], k: int | None = None) -> float:\n",
    "    \"\"\"AP (binary).\"\"\"\n",
    "    if not relevant_set: return 0.0\n",
    "    if k is None: k = len(ranked_ids)\n",
    "    ap, hits = 0.0, 0\n",
    "    for i, rid in enumerate(ranked_ids[:k], start=1):\n",
    "        if rid in relevant_set:\n",
    "            hits += 1\n",
    "            ap += hits / i\n",
    "    return ap / max(1, len(relevant_set))\n",
    "\n",
    "def mrr_at_k(ranked_ids: List[str], relevant_set: set[str], k: int) -> float:\n",
    "    for i, rid in enumerate(ranked_ids[:k], start=1):\n",
    "        if rid in relevant_set:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "def dcg_at_k(gains: List[float], k: int) -> float:\n",
    "    gains = gains[:k]\n",
    "    return sum(g / np.log2(i+2) for i, g in enumerate(gains))\n",
    "\n",
    "def ndcg_at_k(ranked_ids: List[str],\n",
    "              rel_dict: Dict[str, float],  # doc_id -> gain (e.g., 1 or graded)\n",
    "              k: int,\n",
    "              gain_scheme: str = \"exp2\") -> float:\n",
    "    \"\"\"If gain_scheme == 'exp2', use 2^rel - 1; else use rel as gain.\"\"\"\n",
    "    gains = []\n",
    "    for rid in ranked_ids:\n",
    "        rel = rel_dict.get(rid, 0.0)\n",
    "        gains.append((2**rel - 1) if gain_scheme == \"exp2\" else rel)\n",
    "    dcg  = dcg_at_k(gains, k)\n",
    "    # ideal DCG\n",
    "    ideal_gains = sorted(((2**v - 1) if gain_scheme == \"exp2\" else v) for v in rel_dict.values())[::-1]\n",
    "    idcg = dcg_at_k(ideal_gains, k) if ideal_gains else 0.0\n",
    "    return (dcg / idcg) if idcg > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83448d19",
   "metadata": {},
   "source": [
    "### 3 Runner: compute metrics per query and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d712967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(\n",
    "    df_hits: pd.DataFrame,\n",
    "    gt_path_or_df,\n",
    "    id_level: str = \"doc\",       # \"doc\" or \"chunk\"\n",
    "    k_list: Iterable[int] = (1,3,5,10),\n",
    "    score_col: str | None = None,\n",
    "    gain_scheme: str = \"exp2\"    # for nDCG with graded relevance\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns (per_query_df, summary_df)\n",
    "    df_hits must contain:\n",
    "      - query_id (int), doc_id (str), rank (int ascending), and a score column (dense_score/score)\n",
    "      - If id_level=\"chunk\", metrics are computed on (query_id, global_chunk_id) vs GT on doc_id or chunk_id.\n",
    "    Ground truth must contain columns: query_id, doc_id, relevant (>0). (chunk-level GT optionalтАФthen adapt join)\n",
    "    \"\"\"\n",
    "    # Normalize df_hits\n",
    "    hits = df_hits.copy()\n",
    "    if \"query_id\" not in hits.columns or \"doc_id\" not in hits.columns:\n",
    "        raise ValueError(\"df_hits must have columns: query_id, doc_id (chunk_id/global_chunk_id optional).\")\n",
    "    if score_col is None:\n",
    "        score_col = \"dense_score\" if \"dense_score\" in hits.columns else \"score\"\n",
    "    if score_col not in hits.columns:\n",
    "        # if rank exists but no score, synthesize descending score from rank\n",
    "        if \"rank\" in hits.columns:\n",
    "            hits[score_col] = -hits[\"rank\"].astype(float)\n",
    "        else:\n",
    "            raise ValueError(\"df_hits must have a numeric score column or rank.\")\n",
    "\n",
    "    # If evaluating at doc-level but df_hits is chunk-level, roll up\n",
    "    if id_level == \"doc\":\n",
    "        hits = to_doc_level(hits)\n",
    "\n",
    "    # For each query, build ranked list of IDs\n",
    "    hits[\"query_id\"] = hits[\"query_id\"].astype(int)\n",
    "    hits[\"doc_id\"]   = hits[\"doc_id\"].astype(str)\n",
    "    hits = hits.sort_values([\"query_id\", score_col], ascending=[True, False])\n",
    "    ranked_lists = (hits.groupby(\"query_id\")[\"doc_id\"]\n",
    "                         .apply(list)\n",
    "                         .to_dict())\n",
    "\n",
    "    # Prepare ground truth\n",
    "    gt = load_ground_truth(gt_path_or_df)\n",
    "    gt = gt.copy()\n",
    "    gt[\"query_id\"] = gt[\"query_id\"].astype(int)\n",
    "    gt[\"doc_id\"]   = gt[\"doc_id\"].astype(str)\n",
    "\n",
    "    # Build per-query relevant sets and (for nDCG) relevance dictionaries\n",
    "    rel_sets: Dict[int, set[str]] = {qid: set(g[\"doc_id\"]) for qid, g in gt.groupby(\"query_id\")}\n",
    "    rel_dicts: Dict[int, Dict[str, float]] = {\n",
    "        qid: {row.doc_id: float(row.relevant) for _, row in g.iterrows()}\n",
    "        for qid, g in gt.groupby(\"query_id\")\n",
    "    }\n",
    "\n",
    "    # Compute per-query metrics\n",
    "    per_rows = []\n",
    "    for qid, ranked in ranked_lists.items():\n",
    "        rset = rel_sets.get(qid, set())\n",
    "        rmap = rel_dicts.get(qid, {})\n",
    "        row = {\"query_id\": qid, \"num_relevant\": len(rset), \"retrieved\": len(ranked)}\n",
    "        for k in k_list:\n",
    "            row[f\"P@{k}\"]   = precision_at_k(ranked, rset, k)\n",
    "            row[f\"R@{k}\"]   = recall_at_k(ranked, rset, k)\n",
    "            row[f\"nDCG@{k}\"] = ndcg_at_k(ranked, rmap, k, gain_scheme=gain_scheme)\n",
    "        row[\"MRR@{}\".format(max(k_list))] = mrr_at_k(ranked, rset, k=max(k_list))\n",
    "        row[\"MAP\"] = average_precision(ranked, rset, k=max(k_list))\n",
    "        per_rows.append(row)\n",
    "\n",
    "    per_query = pd.DataFrame(per_rows).sort_values(\"query_id\").reset_index(drop=True)\n",
    "\n",
    "    # Summary (macro-average over queries)\n",
    "    agg = {col:\"mean\" for col in per_query.columns if col not in {\"query_id\",\"num_relevant\",\"retrieved\"}}\n",
    "    summary = per_query.agg(agg).to_frame(name=\"mean\").T\n",
    "\n",
    "    return per_query, summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115ef8f",
   "metadata": {},
   "source": [
    "### 4. (Optional) Slice metrics by language/site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_by_slice(df_hits: pd.DataFrame, gt, slice_col: str, **kwargs):\n",
    "    if slice_col not in df_hits.columns:\n",
    "        raise ValueError(f\"{slice_col} not found in df_hits\")\n",
    "    out = []\n",
    "    for val, sub in df_hits.groupby(slice_col):\n",
    "        per_q, summ = evaluate_retrieval(sub, gt, **kwargs)\n",
    "        summ.insert(0, slice_col, val)\n",
    "        summ.insert(1, \"queries\", per_q[\"query_id\"].nunique())\n",
    "        out.append(summ)\n",
    "    return pd.concat(out, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b323f20",
   "metadata": {},
   "source": [
    "### 5. Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321b0814",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_retrieval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Suppose you already have df_hits from your query pipeline (chunk-level).\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1) Evaluate at doc-level (recommended for document search)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/ground/ground_truth_sample.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# columns: query_id, doc_id, relevant\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m per_q, summary \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_retrieval\u001b[49m(\n\u001b[1;32m      5\u001b[0m     df_hits\u001b[38;5;241m=\u001b[39mdf_hits,\n\u001b[1;32m      6\u001b[0m     gt_path_or_df\u001b[38;5;241m=\u001b[39mgt_path,\n\u001b[1;32m      7\u001b[0m     id_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc\u001b[39m\u001b[38;5;124m\"\u001b[39m,          \u001b[38;5;66;03m# or \"chunk\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     k_list\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m      9\u001b[0m     gain_scheme\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp2\u001b[39m\u001b[38;5;124m\"\u001b[39m       \u001b[38;5;66;03m# use graded relevance if available\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m display(per_q\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     12\u001b[0m display(summary)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_retrieval' is not defined"
     ]
    }
   ],
   "source": [
    "# Suppose you already have df_hits from your query pipeline (chunk-level).\n",
    "# 1) Evaluate at doc-level (recommended for document search)\n",
    "gt_path = \"data/ground/ground_truth_sample.csv\"  # columns: query_id, doc_id, relevant\n",
    "per_q, summary = evaluate_retrieval(\n",
    "    df_hits=df_hits,\n",
    "    gt_path_or_df=gt_path,\n",
    "    id_level=\"doc\",          # or \"chunk\"\n",
    "    k_list=(1,3,5,10),\n",
    "    gain_scheme=\"exp2\"       # use graded relevance if available\n",
    ")\n",
    "display(per_q.head())\n",
    "display(summary)\n",
    "\n",
    "# 2) Optional: add lang/site to df_hits before slicing\n",
    "# For example, join with meta on (doc_id, chunk_id) to bring in 'lang' and 'site':\n",
    "# df_hits = df_hits.merge(meta[[\"doc_id\",\"chunk_id\",\"lang\",\"site\",\"title\",\"preview\"]],\n",
    "#                         on=[\"doc_id\",\"chunk_id\"], how=\"left\")\n",
    "\n",
    "# 3) Metrics by language (macro-averaged)\n",
    "# by_lang = evaluate_by_slice(df_hits, gt_path, slice_col=\"lang\", id_level=\"doc\", k_list=(1,3,5,10))\n",
    "# display(by_lang.sort_values(\"mean\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209fd6e",
   "metadata": {},
   "source": [
    "### 7) (Optional) Save results for later analysis & plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1384688",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'per_q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df_sparse_chunks.to_parquet(\"results/sparse_chunks.parquet\", index=False)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_hits\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/sparse_docs.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mper_q\u001b[49m\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/metrics_sparse_per_query.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m summary\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/metrics_sparse_summary.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'per_q' is not defined"
     ]
    }
   ],
   "source": [
    "# df_sparse_chunks.to_parquet(\"results/sparse_chunks.parquet\", index=False)\n",
    "df_hits.to_parquet(\"results/sparse_docs.parquet\", index=False)\n",
    "per_q.to_parquet(\"results/metrics_sparse_per_query.parquet\", index=False)\n",
    "summary.to_csv(\"results/metrics_sparse_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b290bb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e243651",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd14d90",
   "metadata": {},
   "source": [
    "## <b>Keyword based search</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1640ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"DfZP9TzO\")   # ЁЯСИ add this\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f15da",
   "metadata": {},
   "source": [
    "#### Prepare data & bulk-ingest passages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-lingual-semantic-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

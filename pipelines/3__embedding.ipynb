{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b2eed6",
   "metadata": {},
   "source": [
    "# <b>Multilingual Indexing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"   # was \"false\" earlier for safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609600b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Config\n",
    "import os, math, time, numpy as np, pandas as pd, torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee75fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"true\")  # speed up tokenization\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE  = torch.float16 if DEVICE.type == \"cuda\" else torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc101e5",
   "metadata": {},
   "source": [
    "### Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324532d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model (speed tiers):\n",
    "# FAST:    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" (384d)\n",
    "# BALANCE: \"intfloat/multilingual-e5-base\" (768d)\n",
    "# QUALITY: \"intfloat/multilingual-e5-large\" (1024d)\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516faf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME, torch_dtype=(torch.float16 if DEVICE.type==\"cuda\" else None))\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "# Enable fused attention (BetterTransformer) if available\n",
    "try:\n",
    "    from optimum.bettertransformer import BetterTransformer\n",
    "    model = BetterTransformer.transform(model)\n",
    "except Exception:\n",
    "    pass  # it's fine if not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_token_budget(tok, headroom=16, cap_default=512):\n",
    "    ml = getattr(tok, \"model_max_length\", None)\n",
    "    if ml is None or ml > 100_000_000: ml = cap_default\n",
    "    return max(32, int(ml - headroom))\n",
    "TOKEN_BUDGET = model_token_budget(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aaf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_passage_prefix(texts):\n",
    "    # Only E5 needs \"passage: \" prefix\n",
    "    return [f\"passage: {t}\" for t in texts] if \"intfloat/multilingual-e5\" in MODEL_NAME.lower() else texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mean_pool(last_hidden_state, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
    "    summed = (last_hidden_state * mask).sum(dim=1)\n",
    "    counts = mask.sum(dim=1).clamp(min=1e-6)\n",
    "    return summed / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_batch(texts, max_len=TOKEN_BUDGET):\n",
    "    enc = tokenizer(\n",
    "        texts, padding=True, truncation=True, max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    enc = {k: v.to(DEVICE, non_blocking=True) for k, v in enc.items()}\n",
    "    with torch.inference_mode(), (\n",
    "        torch.autocast(device_type=DEVICE.type, dtype=torch.float16) if DEVICE.type==\"cuda\" else torch.no_grad()\n",
    "    ):\n",
    "        out = model(**enc)\n",
    "        pooled = mean_pool(out.last_hidden_state, enc[\"attention_mask\"])\n",
    "        pooled = torch.nn.functional.normalize(pooled, p=2, dim=1)\n",
    "    # Keep float32 for FAISS stability downstream\n",
    "    return pooled.to(torch.float32).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f6e0b",
   "metadata": {},
   "source": [
    "### <b>Create embeddings:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424bf4f",
   "metadata": {},
   "source": [
    "Load Chunked and tokenized data passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ac474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: load the duplicates file\n",
    "df_passages = pd.read_parquet(\"../shared-data-library/out/df_passages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_passages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455f4b6",
   "metadata": {},
   "source": [
    "Input and outputs creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58effca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Inputs & outputs\n",
    "texts = df_passages[\"chunk_text\"].astype(str).tolist()\n",
    "N = len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose batch size\n",
    "BATCH = 768 if DEVICE.type==\"cuda\" else 256   # tune: 512–1024 (GPU), 64–128 (CPU)\n",
    "OUT_DIR = \"data/embed\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine embedding dimensionality once (dry run on 1 example)\n",
    "test_vec = embed_batch(add_passage_prefix([texts[0]]))\n",
    "DIM = test_vec.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a memory-mapped array to write incrementally (resumable)\n",
    "mmap_path = os.path.join(OUT_DIR, f\"{MODEL_NAME.split('/')[-1]}_{DIM}d_50k_float32.mm\")\n",
    "embs = np.memmap(mmap_path, dtype=\"float32\", mode=\"w+\", shape=(N, DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70001356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: resume support — check how many rows already filled (NaNs if unwritten)\n",
    "# For a fresh run, start = 0. If resuming, detect start index from a sidecar file.\n",
    "start = 0\n",
    "sidecar = mmap_path + \".idx\"\n",
    "if os.path.exists(sidecar):\n",
    "    try:\n",
    "        start = int(open(sidecar).read().strip())\n",
    "    except Exception:\n",
    "        start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "for i in tqdm(range(start, N, BATCH), desc=f\"Embedding on {DEVICE}\", unit=\"batch\"):\n",
    "    j = min(i + BATCH, N)\n",
    "    batch = add_passage_prefix(texts[i:j])\n",
    "    vecs = embed_batch(batch, max_len=TOKEN_BUDGET)\n",
    "    embs[i:j, :] = vecs\n",
    "    # Flush progress & write checkpoint index\n",
    "    embs.flush()\n",
    "    with open(sidecar, \"w\") as f:\n",
    "        f.write(str(j))\n",
    "    # Lightweight throughput display\n",
    "    done = j\n",
    "    dt = time.time() - t0\n",
    "    if dt > 0:\n",
    "        tqdm.write(f\"done {done}/{N} | {(done/dt):.1f} chunks/s | ETA {(N-done)/(done/dt+1e-9):.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4fd50",
   "metadata": {},
   "source": [
    "#### Write embedded data to npy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec7799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert memmap to .npy cleanly\n",
    "final_npy = os.path.join(OUT_DIR, f\"{MODEL_NAME.split('/')[-1]}_{DIM}d_50k_float32.npy\")\n",
    "np.save(final_npy, np.asarray(embs))\n",
    "\n",
    "# cleanup resume marker.\n",
    "os.remove(sidecar)  \n",
    "print(\"Saved:\", final_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72405f",
   "metadata": {},
   "source": [
    "### <b>Create DENSE index using FAISS.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e188c6",
   "metadata": {},
   "source": [
    "Stable global ID to align all stores (FAISS / Elasticsearch / SQLite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db574a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Stable global ID to align all stores (FAISS / Elasticsearch / SQLite)\n",
    "df_passages[\"global_chunk_id\"] = (\n",
    "    df_passages[\"doc_id\"].astype(str) + \":\" + df_passages[\"chunk_id\"].astype(int).astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8a8455b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>site</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>chunk_tokens</th>\n",
       "      <th>sent_start</th>\n",
       "      <th>sent_end</th>\n",
       "      <th>preview</th>\n",
       "      <th>global_chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>Երբեք չէի պատկերացնի</td>\n",
       "      <td>en</td>\n",
       "      <td>\"I have never thought that I can do important ...</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I have never thought that I can do important ...</td>\n",
       "      <td>0:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>Երբեք չէի պատկերացնի</td>\n",
       "      <td>en</td>\n",
       "      <td>We spoke to Heghine for a long time and she of...</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We spoke to Heghine for a long time and she of...</td>\n",
       "      <td>1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>Երբեք չէի պատկերացնի</td>\n",
       "      <td>en</td>\n",
       "      <td>responsibility, this is her opportunity to als...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>responsibility, this is her opportunity to als...</td>\n",
       "      <td>1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>Աղետներին պատրաստ դպրոց` սահմանամերձ գյուղում</td>\n",
       "      <td>hy</td>\n",
       "      <td>Տավուշի մարզի Ներքին Ծաղկավան գյուղի դպրոցի VI...</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Տավուշի մարզի Ներքին Ծաղկավան գյուղի դպրոցի VI...</td>\n",
       "      <td>2:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>Աղետներին պատրաստ դպրոց` սահմանամերձ գյուղում</td>\n",
       "      <td>hy</td>\n",
       "      <td>Վերջին երեք տարիներին ՅՈՒՆԻՍԵՖ-ն այս ուղղությա...</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Վերջին երեք տարիներին ՅՈՒՆԻՍԵՖ-ն այս ուղղությա...</td>\n",
       "      <td>3:0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  chunk_id                          site  \\\n",
       "0       0         0  armenia__textcontent_article   \n",
       "1       1         0  armenia__textcontent_article   \n",
       "2       1         1  armenia__textcontent_article   \n",
       "3       2         0  armenia__textcontent_article   \n",
       "4       3         0  armenia__textcontent_article   \n",
       "\n",
       "                                           title lang  \\\n",
       "0                           Երբեք չէի պատկերացնի   en   \n",
       "1                           Երբեք չէի պատկերացնի   en   \n",
       "2                           Երբեք չէի պատկերացնի   en   \n",
       "3  Աղետներին պատրաստ դպրոց` սահմանամերձ գյուղում   hy   \n",
       "4  Աղետներին պատրաստ դպրոց` սահմանամերձ գյուղում   hy   \n",
       "\n",
       "                                          chunk_text  chunk_tokens  \\\n",
       "0  \"I have never thought that I can do important ...           288   \n",
       "1  We spoke to Heghine for a long time and she of...           350   \n",
       "2  responsibility, this is her opportunity to als...            68   \n",
       "3  Տավուշի մարզի Ներքին Ծաղկավան գյուղի դպրոցի VI...           174   \n",
       "4  Վերջին երեք տարիներին ՅՈՒՆԻՍԵՖ-ն այս ուղղությա...           181   \n",
       "\n",
       "   sent_start  sent_end                                            preview  \\\n",
       "0           0         0  \"I have never thought that I can do important ...   \n",
       "1           0         0  We spoke to Heghine for a long time and she of...   \n",
       "2           0         0  responsibility, this is her opportunity to als...   \n",
       "3           0         0  Տավուշի մարզի Ներքին Ծաղկավան գյուղի դպրոցի VI...   \n",
       "4           0         0  Վերջին երեք տարիներին ՅՈՒՆԻՍԵՖ-ն այս ուղղությա...   \n",
       "\n",
       "  global_chunk_id  \n",
       "0             0:0  \n",
       "1             1:0  \n",
       "2             1:1  \n",
       "3             2:0  \n",
       "4             3:0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_passages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e7e09",
   "metadata": {},
   "source": [
    "#### Prepare metadata: Choose the columns you’ll want at retrieval time (add more if you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ec2facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Choose the columns you’ll want at retrieval time (add more if you need)\n",
    "metadata_columns = [\n",
    "    \"global_chunk_id\", \"doc_id\", \"chunk_id\", \"site\", \"lang\",\n",
    "    \"title\", \"preview\", \"chunk_tokens\"\n",
    "]\n",
    "df_meta = df_passages[metadata_columns].rename(columns={\"_site\":\"site\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e457e78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_chunk_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>site</th>\n",
       "      <th>lang</th>\n",
       "      <th>title</th>\n",
       "      <th>preview</th>\n",
       "      <th>chunk_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>en</td>\n",
       "      <td>Երբեք չէի պատկերացնի</td>\n",
       "      <td>\"I have never thought that I can do important ...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>en</td>\n",
       "      <td>Երբեք չէի պատկերացնի</td>\n",
       "      <td>We spoke to Heghine for a long time and she of...</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>en</td>\n",
       "      <td>Երբեք չէի պատկերացնի</td>\n",
       "      <td>responsibility, this is her opportunity to als...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2:0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>hy</td>\n",
       "      <td>Աղետներին պատրաստ դպրոց` սահմանամերձ գյուղում</td>\n",
       "      <td>Տավուշի մարզի Ներքին Ծաղկավան գյուղի դպրոցի VI...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3:0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>armenia__textcontent_article</td>\n",
       "      <td>hy</td>\n",
       "      <td>Աղետներին պատրաստ դպրոց` սահմանամերձ գյուղում</td>\n",
       "      <td>Վերջին երեք տարիներին ՅՈՒՆԻՍԵՖ-ն այս ուղղությա...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  global_chunk_id  doc_id  chunk_id                          site lang  \\\n",
       "0             0:0       0         0  armenia__textcontent_article   en   \n",
       "1             1:0       1         0  armenia__textcontent_article   en   \n",
       "2             1:1       1         1  armenia__textcontent_article   en   \n",
       "3             2:0       2         0  armenia__textcontent_article   hy   \n",
       "4             3:0       3         0  armenia__textcontent_article   hy   \n",
       "\n",
       "                                           title  \\\n",
       "0                           Երբեք չէի պատկերացնի   \n",
       "1                           Երբեք չէի պատկերացնի   \n",
       "2                           Երբեք չէի պատկերացնի   \n",
       "3  Աղետներին պատրաստ դպրոց` սահմանամերձ գյուղում   \n",
       "4  Աղետներին պատրաստ դպրոց` սահմանամերձ գյուղում   \n",
       "\n",
       "                                             preview  chunk_tokens  \n",
       "0  \"I have never thought that I can do important ...           288  \n",
       "1  We spoke to Heghine for a long time and she of...           350  \n",
       "2  responsibility, this is her opportunity to als...            68  \n",
       "3  Տավուշի մարզի Ներքին Ծաղկավան գյուղի դպրոցի VI...           174  \n",
       "4  Վերջին երեք տարիներին ՅՈՒՆԻՍԵՖ-ն այս ուղղությա...           181  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b067d450",
   "metadata": {},
   "source": [
    "#### Save metadata bind with model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "985e3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Save to Parquet (this is the file you’ll later load as meta)\n",
    "# chosen model name\n",
    "MODEL_TAG = \"paraphrase-multilingual-MiniLM-L12-v2\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb433a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved meta: data/embed/paraphrase-multilingual-MiniLM-L12-v2__meta.parquet | rows: 51968\n"
     ]
    }
   ],
   "source": [
    "meta_path = os.path.join('../shared-data-library/metadata/', f\"{MODEL_TAG}__meta.parquet\")\n",
    "df_meta.to_parquet(meta_path, index=False)\n",
    "\n",
    "print(\"Saved meta:\", meta_path, \"| rows:\", len(df_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9caf79d",
   "metadata": {},
   "source": [
    "****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-lingual-semantic-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

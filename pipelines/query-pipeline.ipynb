{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc03c3a1",
   "metadata": {},
   "source": [
    "# Query processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b865727",
   "metadata": {},
   "source": [
    "#### 1. Setup: load model, tokenizer, FAISS index, and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5466fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, torch, faiss\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --- Paths you already created earlier ---\n",
    "META_PATH   = \"data/embeddings_fast/paraphrase-multilingual-MiniLM-L12-v2_passages_meta.parquet\"   # replace\n",
    "FAISS_PATH  = \"data/faiss_index/passages_flatip.faiss\"                # replace\n",
    "\n",
    "# Choose model (speed tiers):\n",
    "# FAST:    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" (384d)\n",
    "# BALANCE: \"intfloat/multilingual-e5-base\" (768d)\n",
    "# QUALITY: \"intfloat/multilingual-e5-large\" (1024d)\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "# --- Load meta and FAISS ---\n",
    "meta  = pd.read_parquet(META_PATH)          # must include global_chunk_id, doc_id, chunk_id, title, preview, site, lang, ...\n",
    "index = faiss.read_index(FAISS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec564439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model / tokenizer ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE  = torch.float16 if DEVICE.type == \"cuda\" else torch.float32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model     = AutoModel.from_pretrained(MODEL_NAME, torch_dtype=(torch.float16 if DEVICE.type==\"cuda\" else None)).to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ddfb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_token_budget(tok, headroom=16, cap_default=512):\n",
    "    m = getattr(tok, \"model_max_length\", None)\n",
    "    if m is None or m > 100_000_000: m = cap_default\n",
    "    return max(32, int(m - headroom))\n",
    "TOKEN_BUDGET = model_token_budget(tokenizer)\n",
    "\n",
    "# E5 uses \"query: \" prefix. Others don't.\n",
    "def add_query_prefix(texts):\n",
    "    return [f\"query: {t}\" for t in texts] if \"intfloat/multilingual-e5\" in MODEL_NAME.lower() else texts\n",
    "\n",
    "@torch.no_grad()\n",
    "def mean_pool(last_hidden_state, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
    "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
    "\n",
    "def l2_normalize_np(x: np.ndarray) -> np.ndarray:\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True) + 1e-12\n",
    "    return x / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201d6d4",
   "metadata": {},
   "source": [
    "### 1. Batch embed queries (fast, safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216de71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_queries(queries: list[str], batch_size: int = 128) -> np.ndarray:\n",
    "    \"\"\"Return (Q, d) L2-normalized float32 embeddings for queries.\"\"\"\n",
    "    vecs = []\n",
    "    queries = add_query_prefix([str(q) for q in queries])\n",
    "    for i in tqdm(range(0, len(queries), batch_size), desc=\"Embedding queries\", unit=\"batch\"):\n",
    "        batch = queries[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=TOKEN_BUDGET, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(DEVICE, non_blocking=True) for k, v in enc.items()}\n",
    "        with torch.inference_mode(), (\n",
    "            torch.autocast(device_type=DEVICE.type, dtype=torch.float16) if DEVICE.type==\"cuda\" else torch.no_grad()\n",
    "        ):\n",
    "            out    = model(**enc)\n",
    "            pooled = mean_pool(out.last_hidden_state, enc[\"attention_mask\"])\n",
    "            pooled = torch.nn.functional.normalize(pooled, p=2, dim=1)   # cosine → IP\n",
    "        vecs.append(pooled.to(torch.float32).cpu().numpy())\n",
    "    return np.vstack(vecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb56499",
   "metadata": {},
   "source": [
    "### 2. Dense search (FAISS) for a batch of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ff3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faiss_search_batch(q_vecs: np.ndarray, top_k: int = 10) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    q_vecs: (Q, d) float32, L2-normalized\n",
    "    returns (scores, indices) each (Q, top_k) with cosine scores (via inner product).\n",
    "    \"\"\"\n",
    "    assert q_vecs.dtype == np.float32\n",
    "    D, I = index.search(q_vecs, top_k)\n",
    "    return D, I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ea5d5",
   "metadata": {},
   "source": [
    "### 3. Assemble results into a tidy DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0819cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_df(queries: list[str], D: np.ndarray, I: np.ndarray, meta: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a long DataFrame with one row per (query, hit).\n",
    "    Columns: query_id, query, rank, dense_score, global_chunk_id, doc_id, chunk_id, title, site, lang, preview, ...\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for qid, (scores, idxs) in enumerate(zip(D, I)):\n",
    "        m = meta.iloc[idxs].copy()\n",
    "        m = m.assign(\n",
    "            query_id = qid,\n",
    "            query    = queries[qid],\n",
    "            rank     = np.arange(1, len(idxs)+1),\n",
    "            dense_score = scores\n",
    "        )\n",
    "        rows.append(m)\n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "    # Ensure IDs exist\n",
    "    if \"global_chunk_id\" not in df.columns:\n",
    "        df[\"global_chunk_id\"] = df[\"doc_id\"].astype(str) + \":\" + df[\"chunk_id\"].astype(int).astype(str)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc259f15",
   "metadata": {},
   "source": [
    "### 4. Optional: roll up chunk → document (max score per doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b45f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_level(df_hits: pd.DataFrame, top_k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep the best chunk per document for each query; then take top_k docs.\n",
    "    \"\"\"\n",
    "    # best chunk per (query_id, doc_id)\n",
    "    best = (df_hits.sort_values([\"query_id\",\"doc_id\",\"dense_score\"], ascending=[True, True, False])\n",
    "                 .groupby([\"query_id\",\"doc_id\"], as_index=False)\n",
    "                 .first())\n",
    "    # rerank per query by score\n",
    "    best[\"rank\"] = best.groupby(\"query_id\")[\"dense_score\"].rank(ascending=False, method=\"first\").astype(int)\n",
    "    best = best.sort_values([\"query_id\",\"rank\"]).groupby(\"query_id\").head(top_k).reset_index(drop=True)\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82340ae",
   "metadata": {},
   "source": [
    "### 5. One call: run a list of queries end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbedab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dense_pipeline(queries: list[str], top_k_chunks: int = 10, top_k_docs: int | None = None):\n",
    "    # 1) embed\n",
    "    q_vecs = embed_queries(queries)\n",
    "    q_vecs = q_vecs.astype(\"float32\")\n",
    "    q_vecs = l2_normalize_np(q_vecs)  # already normalized above; keep for safety\n",
    "\n",
    "    # 2) search\n",
    "    D, I = faiss_search_batch(q_vecs, top_k=top_k_chunks)\n",
    "\n",
    "    # 3) assemble\n",
    "    df_chunks = results_df(queries, D, I, meta)\n",
    "\n",
    "    # 4) optional doc-level rollup\n",
    "    df_docs = doc_level(df_chunks, top_k=top_k_docs) if top_k_docs else None\n",
    "    return df_chunks, df_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2547befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "queries = [\n",
    "    \"child immunization reduces mortality\",      # en\n",
    "    \"política de vacunación infantil\",          # es\n",
    "    \"टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण\",                    # hi\n",
    "    \"儿童免疫接种 对 死亡率 的 影响\"                     # zh\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "033364a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e934548205334b1681294d4adef9fc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding queries:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_hits, df_docs = run_dense_pipeline(queries, top_k_chunks=20, top_k_docs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ed09e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>dense_score</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862851</td>\n",
       "      <td>15900</td>\n",
       "      <td>0</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>hi</td>\n",
       "      <td>चिकित्सा के क्षेत्र में टीकाकरण का अहम योगदान ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797363</td>\n",
       "      <td>14211</td>\n",
       "      <td>5</td>\n",
       "      <td>اليونيسف ومنظمة الصحة العالمية تحذِّران من اجت...</td>\n",
       "      <td>ar</td>\n",
       "      <td>لشرح أهمية اللقاحات؛ سد الفجوات في تغطية التحص...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>3</td>\n",
       "      <td>0.776559</td>\n",
       "      <td>18018</td>\n",
       "      <td>4</td>\n",
       "      <td>Зміцнення довіри до продовження планової імуні...</td>\n",
       "      <td>uk</td>\n",
       "      <td>ключових осіб, які приймають рішення, пов'язан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>4</td>\n",
       "      <td>0.767746</td>\n",
       "      <td>14644</td>\n",
       "      <td>3</td>\n",
       "      <td>Dix-huit millions de doses du tout premier vac...</td>\n",
       "      <td>fr</td>\n",
       "      <td>ès et traiter la maladie depuis longtemps, mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>5</td>\n",
       "      <td>0.763638</td>\n",
       "      <td>13699</td>\n",
       "      <td>5</td>\n",
       "      <td>خدمات التحصين تبدأ بالتعافي ببطء من التعطيلات ...</td>\n",
       "      <td>ar</td>\n",
       "      <td>اث والتطوير في مجال اللقاحات، وضمان استمرارية ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>6</td>\n",
       "      <td>0.744338</td>\n",
       "      <td>8669</td>\n",
       "      <td>2</td>\n",
       "      <td>123,000 children in Europe and Central Asia ar...</td>\n",
       "      <td>en</td>\n",
       "      <td>combination of the number of vaccines in a cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>7</td>\n",
       "      <td>0.743962</td>\n",
       "      <td>20165</td>\n",
       "      <td>2</td>\n",
       "      <td>ЮНІСЕФ доставив в Україну 340 тисяч доз оральн...</td>\n",
       "      <td>uk</td>\n",
       "      <td>допомогою щеплень. Окрім того, аби забезпечити...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>8</td>\n",
       "      <td>0.735053</td>\n",
       "      <td>4424</td>\n",
       "      <td>2</td>\n",
       "      <td>告诉你疫苗那些事儿</td>\n",
       "      <td>zh</td>\n",
       "      <td>传播出去)。 新浪国际:接种疫苗对孩子有什么好处? 朱徐: 有些</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>9</td>\n",
       "      <td>0.728540</td>\n",
       "      <td>19340</td>\n",
       "      <td>6</td>\n",
       "      <td>ВООЗ та ЮНІСЕФ застерігають щодо зниження рівн...</td>\n",
       "      <td>uk</td>\n",
       "      <td>та профілактики захворювань в США (CDC), Інсти...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण</td>\n",
       "      <td>10</td>\n",
       "      <td>0.727539</td>\n",
       "      <td>13216</td>\n",
       "      <td>8</td>\n",
       "      <td>80 millions d'enfants de moins d’un an risquen...</td>\n",
       "      <td>fr</td>\n",
       "      <td>i, l'Alliance du Vaccin. Son objectif est d'ér...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id                                        query  rank  dense_score  \\\n",
       "40         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     1     0.862851   \n",
       "41         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     2     0.797363   \n",
       "42         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     3     0.776559   \n",
       "43         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     4     0.767746   \n",
       "44         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     5     0.763638   \n",
       "45         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     6     0.744338   \n",
       "46         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     7     0.743962   \n",
       "47         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     8     0.735053   \n",
       "48         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण     9     0.728540   \n",
       "49         2  टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण    10     0.727539   \n",
       "\n",
       "    doc_id  chunk_id                                              title lang  \\\n",
       "40   15900         0        टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण   hi   \n",
       "41   14211         5  اليونيسف ومنظمة الصحة العالمية تحذِّران من اجت...   ar   \n",
       "42   18018         4  Зміцнення довіри до продовження планової імуні...   uk   \n",
       "43   14644         3  Dix-huit millions de doses du tout premier vac...   fr   \n",
       "44   13699         5  خدمات التحصين تبدأ بالتعافي ببطء من التعطيلات ...   ar   \n",
       "45    8669         2  123,000 children in Europe and Central Asia ar...   en   \n",
       "46   20165         2  ЮНІСЕФ доставив в Україну 340 тисяч доз оральн...   uk   \n",
       "47    4424         2                                          告诉你疫苗那些事儿   zh   \n",
       "48   19340         6  ВООЗ та ЮНІСЕФ застерігають щодо зниження рівн...   uk   \n",
       "49   13216         8  80 millions d'enfants de moins d’un an risquen...   fr   \n",
       "\n",
       "                                              preview  \n",
       "40  चिकित्सा के क्षेत्र में टीकाकरण का अहम योगदान ...  \n",
       "41  لشرح أهمية اللقاحات؛ سد الفجوات في تغطية التحص...  \n",
       "42  ключових осіб, які приймають рішення, пов'язан...  \n",
       "43  ès et traiter la maladie depuis longtemps, mai...  \n",
       "44  اث والتطوير في مجال اللقاحات، وضمان استمرارية ...  \n",
       "45  combination of the number of vaccines in a cou...  \n",
       "46  допомогою щеплень. Окрім того, аби забезпечити...  \n",
       "47                   传播出去)。 新浪国际:接种疫苗对孩子有什么好处? 朱徐: 有些  \n",
       "48  та профілактики захворювань в США (CDC), Інсти...  \n",
       "49  i, l'Alliance du Vaccin. Son objectif est d'ér...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect\n",
    "df_hits[df_hits['query'] == 'टीकाकरण क्यों जरूरी है इसके पांच मुख्य कारण'].head(10)[[\"query_id\",\"query\",\"rank\",\"dense_score\",\"doc_id\",\"chunk_id\",\"title\",\"lang\",\"preview\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0bb63",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fca18f",
   "metadata": {},
   "source": [
    "## <b>Query Evaluation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa5fc57",
   "metadata": {},
   "source": [
    "### 1. Helpers: roll up to doc-level (optional) and normalize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Iterable, Dict, List\n",
    "\n",
    "def to_doc_level(df_hits: pd.DataFrame, top_k: int | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Collapse chunk-level results to doc-level by keeping the best chunk per (query_id, doc_id),\n",
    "    then re-ranking by score. Assumes columns: query_id, doc_id, dense_score (or score), rank.\n",
    "    \"\"\"\n",
    "    score_col = \"dense_score\" if \"dense_score\" in df_hits.columns else \"score\"\n",
    "    if score_col not in df_hits.columns:\n",
    "        raise ValueError(\"df_hits must contain 'dense_score' or 'score' column.\")\n",
    "    # keep best chunk per (query, doc)\n",
    "    best = (df_hits\n",
    "            .sort_values([\"query_id\",\"doc_id\",score_col], ascending=[True, True, False])\n",
    "            .groupby([\"query_id\",\"doc_id\"], as_index=False)\n",
    "            .first())\n",
    "    # rerank within query\n",
    "    best[\"rank\"] = best.groupby(\"query_id\")[score_col].rank(ascending=False, method=\"first\").astype(int)\n",
    "    best = best.sort_values([\"query_id\",\"rank\"])\n",
    "    if top_k:\n",
    "        best = best.groupby(\"query_id\").head(top_k).reset_index(drop=True)\n",
    "    return best\n",
    "\n",
    "def load_ground_truth(gt_path_or_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expect columns: query_id, doc_id, relevant (0/1 or graded).\n",
    "    Keeps only rows with relevant > 0.\n",
    "    \"\"\"\n",
    "    gt = gt_path_or_df if isinstance(gt_path_or_df, pd.DataFrame) else pd.read_csv(gt_path_or_df)\n",
    "    # Basic sanity\n",
    "    required = {\"query_id\",\"doc_id\",\"relevant\"}\n",
    "    missing = required - set(gt.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Ground truth missing columns: {missing}\")\n",
    "    gt = gt.copy()\n",
    "    # Coerce types\n",
    "    gt[\"query_id\"] = gt[\"query_id\"].astype(int)\n",
    "    gt[\"doc_id\"]   = gt[\"doc_id\"].astype(str)\n",
    "    # Keep nonzero as relevant; preserve graded values for nDCG\n",
    "    gt = gt[gt[\"relevant\"] > 0].reset_index(drop=True)\n",
    "    return gt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77b7e6",
   "metadata": {},
   "source": [
    "### 2. Metrics (P@k, Recall@k, MRR, MAP, nDCG) — binary or graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ba0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ranked_ids: List[str], relevant_set: set[str], k: int) -> float:\n",
    "    if k == 0: return 0.0\n",
    "    topk = ranked_ids[:k]\n",
    "    hits = sum(1 for x in topk if x in relevant_set)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(ranked_ids: List[str], relevant_set: set[str], k: int) -> float:\n",
    "    if not relevant_set: return 0.0\n",
    "    topk = ranked_ids[:k]\n",
    "    hits = sum(1 for x in topk if x in relevant_set)\n",
    "    return hits / len(relevant_set)\n",
    "\n",
    "def average_precision(ranked_ids: List[str], relevant_set: set[str], k: int | None = None) -> float:\n",
    "    \"\"\"AP (binary).\"\"\"\n",
    "    if not relevant_set: return 0.0\n",
    "    if k is None: k = len(ranked_ids)\n",
    "    ap, hits = 0.0, 0\n",
    "    for i, rid in enumerate(ranked_ids[:k], start=1):\n",
    "        if rid in relevant_set:\n",
    "            hits += 1\n",
    "            ap += hits / i\n",
    "    return ap / max(1, len(relevant_set))\n",
    "\n",
    "def mrr_at_k(ranked_ids: List[str], relevant_set: set[str], k: int) -> float:\n",
    "    for i, rid in enumerate(ranked_ids[:k], start=1):\n",
    "        if rid in relevant_set:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "def dcg_at_k(gains: List[float], k: int) -> float:\n",
    "    gains = gains[:k]\n",
    "    return sum(g / np.log2(i+2) for i, g in enumerate(gains))\n",
    "\n",
    "def ndcg_at_k(ranked_ids: List[str],\n",
    "              rel_dict: Dict[str, float],  # doc_id -> gain (e.g., 1 or graded)\n",
    "              k: int,\n",
    "              gain_scheme: str = \"exp2\") -> float:\n",
    "    \"\"\"If gain_scheme == 'exp2', use 2^rel - 1; else use rel as gain.\"\"\"\n",
    "    gains = []\n",
    "    for rid in ranked_ids:\n",
    "        rel = rel_dict.get(rid, 0.0)\n",
    "        gains.append((2**rel - 1) if gain_scheme == \"exp2\" else rel)\n",
    "    dcg  = dcg_at_k(gains, k)\n",
    "    # ideal DCG\n",
    "    ideal_gains = sorted(((2**v - 1) if gain_scheme == \"exp2\" else v) for v in rel_dict.values())[::-1]\n",
    "    idcg = dcg_at_k(ideal_gains, k) if ideal_gains else 0.0\n",
    "    return (dcg / idcg) if idcg > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83448d19",
   "metadata": {},
   "source": [
    "### 3 Runner: compute metrics per query and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d712967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(\n",
    "    df_hits: pd.DataFrame,\n",
    "    gt_path_or_df,\n",
    "    id_level: str = \"doc\",       # \"doc\" or \"chunk\"\n",
    "    k_list: Iterable[int] = (1,3,5,10),\n",
    "    score_col: str | None = None,\n",
    "    gain_scheme: str = \"exp2\"    # for nDCG with graded relevance\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns (per_query_df, summary_df)\n",
    "    df_hits must contain:\n",
    "      - query_id (int), doc_id (str), rank (int ascending), and a score column (dense_score/score)\n",
    "      - If id_level=\"chunk\", metrics are computed on (query_id, global_chunk_id) vs GT on doc_id or chunk_id.\n",
    "    Ground truth must contain columns: query_id, doc_id, relevant (>0). (chunk-level GT optional—then adapt join)\n",
    "    \"\"\"\n",
    "    # Normalize df_hits\n",
    "    hits = df_hits.copy()\n",
    "    if \"query_id\" not in hits.columns or \"doc_id\" not in hits.columns:\n",
    "        raise ValueError(\"df_hits must have columns: query_id, doc_id (chunk_id/global_chunk_id optional).\")\n",
    "    if score_col is None:\n",
    "        score_col = \"dense_score\" if \"dense_score\" in hits.columns else \"score\"\n",
    "    if score_col not in hits.columns:\n",
    "        # if rank exists but no score, synthesize descending score from rank\n",
    "        if \"rank\" in hits.columns:\n",
    "            hits[score_col] = -hits[\"rank\"].astype(float)\n",
    "        else:\n",
    "            raise ValueError(\"df_hits must have a numeric score column or rank.\")\n",
    "\n",
    "    # If evaluating at doc-level but df_hits is chunk-level, roll up\n",
    "    if id_level == \"doc\":\n",
    "        hits = to_doc_level(hits)\n",
    "\n",
    "    # For each query, build ranked list of IDs\n",
    "    hits[\"query_id\"] = hits[\"query_id\"].astype(int)\n",
    "    hits[\"doc_id\"]   = hits[\"doc_id\"].astype(str)\n",
    "    hits = hits.sort_values([\"query_id\", score_col], ascending=[True, False])\n",
    "    ranked_lists = (hits.groupby(\"query_id\")[\"doc_id\"]\n",
    "                         .apply(list)\n",
    "                         .to_dict())\n",
    "\n",
    "    # Prepare ground truth\n",
    "    gt = load_ground_truth(gt_path_or_df)\n",
    "    gt = gt.copy()\n",
    "    gt[\"query_id\"] = gt[\"query_id\"].astype(int)\n",
    "    gt[\"doc_id\"]   = gt[\"doc_id\"].astype(str)\n",
    "\n",
    "    # Build per-query relevant sets and (for nDCG) relevance dictionaries\n",
    "    rel_sets: Dict[int, set[str]] = {qid: set(g[\"doc_id\"]) for qid, g in gt.groupby(\"query_id\")}\n",
    "    rel_dicts: Dict[int, Dict[str, float]] = {\n",
    "        qid: {row.doc_id: float(row.relevant) for _, row in g.iterrows()}\n",
    "        for qid, g in gt.groupby(\"query_id\")\n",
    "    }\n",
    "\n",
    "    # Compute per-query metrics\n",
    "    per_rows = []\n",
    "    for qid, ranked in ranked_lists.items():\n",
    "        rset = rel_sets.get(qid, set())\n",
    "        rmap = rel_dicts.get(qid, {})\n",
    "        row = {\"query_id\": qid, \"num_relevant\": len(rset), \"retrieved\": len(ranked)}\n",
    "        for k in k_list:\n",
    "            row[f\"P@{k}\"]   = precision_at_k(ranked, rset, k)\n",
    "            row[f\"R@{k}\"]   = recall_at_k(ranked, rset, k)\n",
    "            row[f\"nDCG@{k}\"] = ndcg_at_k(ranked, rmap, k, gain_scheme=gain_scheme)\n",
    "        row[\"MRR@{}\".format(max(k_list))] = mrr_at_k(ranked, rset, k=max(k_list))\n",
    "        row[\"MAP\"] = average_precision(ranked, rset, k=max(k_list))\n",
    "        per_rows.append(row)\n",
    "\n",
    "    per_query = pd.DataFrame(per_rows).sort_values(\"query_id\").reset_index(drop=True)\n",
    "\n",
    "    # Summary (macro-average over queries)\n",
    "    agg = {col:\"mean\" for col in per_query.columns if col not in {\"query_id\",\"num_relevant\",\"retrieved\"}}\n",
    "    summary = per_query.agg(agg).to_frame(name=\"mean\").T\n",
    "\n",
    "    return per_query, summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115ef8f",
   "metadata": {},
   "source": [
    "### 4. (Optional) Slice metrics by language/site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_by_slice(df_hits: pd.DataFrame, gt, slice_col: str, **kwargs):\n",
    "    if slice_col not in df_hits.columns:\n",
    "        raise ValueError(f\"{slice_col} not found in df_hits\")\n",
    "    out = []\n",
    "    for val, sub in df_hits.groupby(slice_col):\n",
    "        per_q, summ = evaluate_retrieval(sub, gt, **kwargs)\n",
    "        summ.insert(0, slice_col, val)\n",
    "        summ.insert(1, \"queries\", per_q[\"query_id\"].nunique())\n",
    "        out.append(summ)\n",
    "    return pd.concat(out, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b323f20",
   "metadata": {},
   "source": [
    "### 5. Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321b0814",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_retrieval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Suppose you already have df_hits from your query pipeline (chunk-level).\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1) Evaluate at doc-level (recommended for document search)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/ground/ground_truth_sample.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# columns: query_id, doc_id, relevant\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m per_q, summary \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_retrieval\u001b[49m(\n\u001b[1;32m      5\u001b[0m     df_hits\u001b[38;5;241m=\u001b[39mdf_hits,\n\u001b[1;32m      6\u001b[0m     gt_path_or_df\u001b[38;5;241m=\u001b[39mgt_path,\n\u001b[1;32m      7\u001b[0m     id_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc\u001b[39m\u001b[38;5;124m\"\u001b[39m,          \u001b[38;5;66;03m# or \"chunk\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     k_list\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m      9\u001b[0m     gain_scheme\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp2\u001b[39m\u001b[38;5;124m\"\u001b[39m       \u001b[38;5;66;03m# use graded relevance if available\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m display(per_q\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     12\u001b[0m display(summary)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_retrieval' is not defined"
     ]
    }
   ],
   "source": [
    "# Suppose you already have df_hits from your query pipeline (chunk-level).\n",
    "# 1) Evaluate at doc-level (recommended for document search)\n",
    "gt_path = \"data/ground/ground_truth_sample.csv\"  # columns: query_id, doc_id, relevant\n",
    "per_q, summary = evaluate_retrieval(\n",
    "    df_hits=df_hits,\n",
    "    gt_path_or_df=gt_path,\n",
    "    id_level=\"doc\",          # or \"chunk\"\n",
    "    k_list=(1,3,5,10),\n",
    "    gain_scheme=\"exp2\"       # use graded relevance if available\n",
    ")\n",
    "display(per_q.head())\n",
    "display(summary)\n",
    "\n",
    "# 2) Optional: add lang/site to df_hits before slicing\n",
    "# For example, join with meta on (doc_id, chunk_id) to bring in 'lang' and 'site':\n",
    "# df_hits = df_hits.merge(meta[[\"doc_id\",\"chunk_id\",\"lang\",\"site\",\"title\",\"preview\"]],\n",
    "#                         on=[\"doc_id\",\"chunk_id\"], how=\"left\")\n",
    "\n",
    "# 3) Metrics by language (macro-averaged)\n",
    "# by_lang = evaluate_by_slice(df_hits, gt_path, slice_col=\"lang\", id_level=\"doc\", k_list=(1,3,5,10))\n",
    "# display(by_lang.sort_values(\"mean\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209fd6e",
   "metadata": {},
   "source": [
    "### 7) (Optional) Save results for later analysis & plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1384688",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'per_q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df_sparse_chunks.to_parquet(\"results/sparse_chunks.parquet\", index=False)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_hits\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/sparse_docs.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mper_q\u001b[49m\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/metrics_sparse_per_query.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m summary\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/metrics_sparse_summary.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'per_q' is not defined"
     ]
    }
   ],
   "source": [
    "# df_sparse_chunks.to_parquet(\"results/sparse_chunks.parquet\", index=False)\n",
    "df_hits.to_parquet(\"results/sparse_docs.parquet\", index=False)\n",
    "per_q.to_parquet(\"results/metrics_sparse_per_query.parquet\", index=False)\n",
    "summary.to_csv(\"results/metrics_sparse_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b290bb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e243651",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd14d90",
   "metadata": {},
   "source": [
    "## <b>Keyword based search</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1640ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"DfZP9TzO\")   # 👈 add this\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f15da",
   "metadata": {},
   "source": [
    "#### Prepare data & bulk-ingest passages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-lingual-semantic-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
